{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4df6262c-4aef-4825-a865-677a341d708b",
   "metadata": {
    "id": "4df6262c-4aef-4825-a865-677a341d708b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0bfbd5-bef9-4221-8c21-763703d32d26",
   "metadata": {
    "id": "6b0bfbd5-bef9-4221-8c21-763703d32d26"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b7f6b-04d1-42ab-9ce4-f28c5dbd7d43",
   "metadata": {
    "id": "518b7f6b-04d1-42ab-9ce4-f28c5dbd7d43"
   },
   "source": [
    "## SOME INSIGHTS OF THE DATASET\n",
    "#### This data set consists of 3 columns: dialog, act and emotion. The dialog column has one conversation, consisting of multiple dialogs. And for each sentence we a classification of it's act and emotion. Secondly, the dtype of all the columns are object and they are string of list of string ie, \"['xyz', 'abc', 'pqr']\". Similarly for the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1d4a4d-6566-4984-8644-260414211191",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a1d4a4d-6566-4984-8644-260414211191",
    "outputId": "72d525fa-dec2-43b8-e446-10f6e7b67df0"
   },
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab99adbf-cb06-49a2-a016-267ca22539b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "ab99adbf-cb06-49a2-a016-267ca22539b8",
    "outputId": "e8005b77-654b-4df9-bc67-b8aaa0ebe41d"
   },
   "outputs": [],
   "source": [
    "#df.iloc[0].dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677ea520-4505-4597-9390-311cfb22ff1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "677ea520-4505-4597-9390-311cfb22ff1a",
    "outputId": "dc6b6bbc-2b73-45ea-f9ff-df20e1a927f7"
   },
   "outputs": [],
   "source": [
    "#df.iloc[0].act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cad1183-3186-4fdb-85ab-51d87677e8c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "0cad1183-3186-4fdb-85ab-51d87677e8c3",
    "outputId": "b3bc8874-c852-4c5a-da5b-217fbc97a29c"
   },
   "outputs": [],
   "source": [
    "#df.iloc[0].emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7ead85-64f0-49d8-a879-5e099480f70d",
   "metadata": {
    "id": "bc7ead85-64f0-49d8-a879-5e099480f70d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import re\\n\\ndef parse_dialog(dialog_str):\\n    if not isinstance(dialog_str, str):\\n        return []\\n    matches = re.findall(r\"\\'(.*?)\\'|\"(.*?)\"\", dialog_str)\\n    return [m[0] or m[1] for m in matches]\\n\\n\\ndef parse_labels(label_str):\\n    if not isinstance(label_str, str):\\n        return []\\n    return list(map(int, label_str.strip(\"[]\").split()))\\n\\n\\ndef flatten_dialog_dataset(df):\\n    rows = []\\n\\n    for _, row in df.iterrows():\\n        sentences = parse_dialog(row[\"dialog\"])\\n        acts = parse_labels(row[\"act\"])\\n        emotions = parse_labels(row[\"emotion\"])\\n\\n        if not (len(sentences) == len(acts) == len(emotions)):\\n            continue  # skip broken rows\\n\\n        for s, a, e in zip(sentences, acts, emotions):\\n            rows.append({\\n                \"sentence\": s.strip(),\\n                \"act\": a,\\n                \"emotion\": e\\n            })\\n\\n    return pd.DataFrame(rows)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import re\n",
    "\n",
    "def parse_dialog(dialog_str):\n",
    "    if not isinstance(dialog_str, str):\n",
    "        return []\n",
    "    matches = re.findall(r\"'(.*?)'|\\\"(.*?)\\\"\", dialog_str)\n",
    "    return [m[0] or m[1] for m in matches]\n",
    "\n",
    "\n",
    "def parse_labels(label_str):\n",
    "    if not isinstance(label_str, str):\n",
    "        return []\n",
    "    return list(map(int, label_str.strip(\"[]\").split()))\n",
    "\n",
    "\n",
    "def flatten_dialog_dataset(df):\n",
    "    rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sentences = parse_dialog(row[\"dialog\"])\n",
    "        acts = parse_labels(row[\"act\"])\n",
    "        emotions = parse_labels(row[\"emotion\"])\n",
    "\n",
    "        if not (len(sentences) == len(acts) == len(emotions)):\n",
    "            continue  # skip broken rows\n",
    "\n",
    "        for s, a, e in zip(sentences, acts, emotions):\n",
    "            rows.append({\n",
    "                \"sentence\": s.strip(),\n",
    "                \"act\": a,\n",
    "                \"emotion\": e\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0385934e-6c6c-465f-8fa4-0f9b773ec9c1",
   "metadata": {
    "id": "7327046a-c1f3-4c87-be00-305786c18dcd"
   },
   "outputs": [],
   "source": [
    "#new_df = flatten_dialog_dataset(df)\n",
    "\n",
    "#new_df[\"sentence\"] = new_df[\"sentence\"].str.lower().apply(wordpunct_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Ey1ysEKoD9Ua",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ey1ysEKoD9Ua",
    "outputId": "f5233ffc-1b45-465e-e0cc-902bca7304eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dell\\anaconda3\\lib\\site-packages (from smart_open>=1.8.1->gensim) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894dc035-3194-49cc-8eff-e4e1cb121028",
   "metadata": {
    "id": "894dc035-3194-49cc-8eff-e4e1cb121028"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from gensim.test.utils import common_texts\\nfrom gensim.models import Word2Vec'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97984a7a-559a-4f17-9d20-51bbc9deaf00",
   "metadata": {
    "id": "97984a7a-559a-4f17-9d20-51bbc9deaf00"
   },
   "outputs": [],
   "source": [
    "#corpus = new_df['sentence'].tolist()\n",
    "#model = Word2Vec(sentences=corpus, vector_size=256, window=7, sg=1, min_count=1, epochs=18, sample = 1e-3, negative=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3443f55-4334-4d2e-857d-dce1450b259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.save(\"word2vec_256.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86bca3a1-0227-4919-b20c-29881e10a388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from gensim.models import KeyedVectors\\nwv = KeyedVectors.load(\"word2vec_256.kv\")'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load(\"word2vec_256.kv\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198100e7-7fd9-4a8a-8d65-b415ae3581c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "198100e7-7fd9-4a8a-8d65-b415ae3581c3",
    "outputId": "05df11a9-fc53-430d-d6f5-299b27d3161b"
   },
   "outputs": [],
   "source": [
    "#wv.most_similar('tired', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "931cf5c2-fa33-474f-8e0d-36580b723c6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "931cf5c2-fa33-474f-8e0d-36580b723c6a",
    "outputId": "0cb050ae-39e1-4d1d-ba08-96da62f0bfc1"
   },
   "outputs": [],
   "source": [
    "#new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a999bd2a-5e34-4220-9083-b3a9df0c0157",
   "metadata": {
    "id": "a999bd2a-5e34-4220-9083-b3a9df0c0157"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "V8ZD8Se5hXvu",
   "metadata": {
    "id": "V8ZD8Se5hXvu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def build_sentence_embeddings(new_df, wv):\\n  def sentence_to_matrix(tokens):\\n    vectors = []\\n    for token in tokens:\\n      if token in wv:\\n        vectors.append(wv[token])\\n      #else:\\n        #vectors.append(np.zeros(embedding_dim))\\n\\n    return np.vstack(vectors)\\n\\n  new_df['embedding_matrix'] = new_df['sentence'].apply(sentence_to_matrix)\\n\\n  return new_df\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def build_sentence_embeddings(new_df, wv):\n",
    "  def sentence_to_matrix(tokens):\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "      if token in wv:\n",
    "        vectors.append(wv[token])\n",
    "      #else:\n",
    "        #vectors.append(np.zeros(embedding_dim))\n",
    "\n",
    "    return np.vstack(vectors)\n",
    "\n",
    "  new_df['embedding_matrix'] = new_df['sentence'].apply(sentence_to_matrix)\n",
    "\n",
    "  return new_df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "JSmmlO2FHLp1",
   "metadata": {
    "id": "JSmmlO2FHLp1"
   },
   "outputs": [],
   "source": [
    "#df = build_sentence_embeddings(new_df, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "OpVp4i0A3K64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpVp4i0A3K64",
    "outputId": "03f2bc75-b62a-4af4-ed9d-49691adf8c77"
   },
   "outputs": [],
   "source": [
    "#df.iloc[0].embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eT2QSnheJ-6B",
   "metadata": {
    "id": "eT2QSnheJ-6B"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def positional_encodings(max_len, d_model=256):\\n\\n  PE = np.zeros((max_len, d_model))\\n\\n  for pos in range(max_len):\\n    for i in range(d_model//2):\\n\\n      PE[pos, 2*i] = np.sin((pos) / (10000**(2*i / 512)))\\n      PE[pos, 2*i+1] = np.cos((pos) / (10000**(2*i / 512)))\\n\\n  return PE'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def positional_encodings(max_len, d_model=256):\n",
    "\n",
    "  PE = np.zeros((max_len, d_model))\n",
    "\n",
    "  for pos in range(max_len):\n",
    "    for i in range(d_model//2):\n",
    "\n",
    "      PE[pos, 2*i] = np.sin((pos) / (10000**(2*i / 512)))\n",
    "      PE[pos, 2*i+1] = np.cos((pos) / (10000**(2*i / 512)))\n",
    "\n",
    "  return PE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9cktH_OQMuy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "d9cktH_OQMuy",
    "outputId": "8d03acc0-83db-4662-fe28-d2c863e1aecb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df['sentence'].apply(len).describe()\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df['sentence'].apply(len).describe()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e91f6ca-7365-49bc-8f8b-d5b848b023ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PE = positional_encodings(max_len=294, d_model=256)\\ndf['embedding_matrix'] = df['embedding_matrix'].apply(lambda x: x + PE[:x.shape[0]])\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PE = positional_encodings(max_len=294, d_model=256)\n",
    "df['embedding_matrix'] = df['embedding_matrix'].apply(lambda x: x + PE[:x.shape[0]])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ea6fae6-c285-455d-a6be-c858ce9a700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59ee332e-8c54-4cfd-8e2b-9160c37d6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle(\"dataset_with_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd52882-a302-4a69-b97d-22fd14910c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b902a-09e0-4a93-9e3e-e0b9b681a72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57603d37-f575-4f42-8496-d0413c7c2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import torch\n",
    "import numpy as np\n",
    "df['embedding_matrix'] = df['embedding_matrix'].apply(lambda x: torch.from_numpy(x))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae52a9-5698-4811-bf3b-e547da39a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle(\"dataset_with_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31d58711-c6b8-46b1-87d4-205c32656da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>act</th>\n",
       "      <th>emotion</th>\n",
       "      <th>embedding_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[say, ,, jim, ,, how, about, going, for, a, fe...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.1942, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[you, know, that, is, tempting, but, is, reall...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(0.0734, dtype=torch.float64), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[what, do, you, mean, ?, it, will, help, us, t...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.0327, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[do, you, really, think, so, ?, i, don, ', t, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.0939, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, guess, you, are, right, ., but, what, shal...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.0713, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86786</th>\n",
       "      <td>[i, want, a, pair, of, locus, .]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.0713, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86787</th>\n",
       "      <td>[take, a, look, at, the, ones, on, display, ,,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.3741, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86788</th>\n",
       "      <td>[i, need, size, 41, .]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.0713, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86789</th>\n",
       "      <td>[could, i, have, the, check, ,, please, ?]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.2140, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86790</th>\n",
       "      <td>[okay, ., i, ', ll, just, be, a, minute, .]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(-0.0769, dtype=torch.float64), tensor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86791 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  act  emotion  \\\n",
       "0      [say, ,, jim, ,, how, about, going, for, a, fe...    3        0   \n",
       "1      [you, know, that, is, tempting, but, is, reall...    4        0   \n",
       "2      [what, do, you, mean, ?, it, will, help, us, t...    2        0   \n",
       "3      [do, you, really, think, so, ?, i, don, ', t, ...    2        0   \n",
       "4      [i, guess, you, are, right, ., but, what, shal...    2        0   \n",
       "...                                                  ...  ...      ...   \n",
       "86786                   [i, want, a, pair, of, locus, .]    3        0   \n",
       "86787  [take, a, look, at, the, ones, on, display, ,,...    4        0   \n",
       "86788                             [i, need, size, 41, .]    3        0   \n",
       "86789         [could, i, have, the, check, ,, please, ?]    3        0   \n",
       "86790        [okay, ., i, ', ll, just, be, a, minute, .]    4        0   \n",
       "\n",
       "                                        embedding_matrix  \n",
       "0      [[tensor(-0.1942, dtype=torch.float64), tensor...  \n",
       "1      [[tensor(0.0734, dtype=torch.float64), tensor(...  \n",
       "2      [[tensor(-0.0327, dtype=torch.float64), tensor...  \n",
       "3      [[tensor(-0.0939, dtype=torch.float64), tensor...  \n",
       "4      [[tensor(-0.0713, dtype=torch.float64), tensor...  \n",
       "...                                                  ...  \n",
       "86786  [[tensor(-0.0713, dtype=torch.float64), tensor...  \n",
       "86787  [[tensor(-0.3741, dtype=torch.float64), tensor...  \n",
       "86788  [[tensor(-0.0713, dtype=torch.float64), tensor...  \n",
       "86789  [[tensor(-0.2140, dtype=torch.float64), tensor...  \n",
       "86790  [[tensor(-0.0769, dtype=torch.float64), tensor...  \n",
       "\n",
       "[86791 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68cdf5-b9dd-4f9f-82bd-61cab25e3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['sentence'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4098c56a-dc4e-4dee-9743-18ac0623ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096d8293-5562-4cd9-abc7-da1ccb249f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"dataset_with_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6137393b-a377-48b4-8e60-111c31f35c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.sentences = df[\"embedding_matrix\"].tolist()\n",
    "        self.labels = df['emotion'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx], self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55a03b5a-a446-4d3a-83ab-0b5778f88774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # batch = [(sentence_tensor, label), ...]\n",
    "\n",
    "    sentences, labels = zip(*batch)  # unzip\n",
    "    \n",
    "    lengths = torch.tensor([x.shape[0] for x in sentences])  # (B,)\n",
    "    \n",
    "    # Pad sentence tensors\n",
    "    padded = pad_sequence(batch, batch_first=True)  # (B, L, d_model)\n",
    "    \n",
    "    # Create attention mask\n",
    "    max_len = padded.shape[1]\n",
    "    mask = torch.arange(max_len).expand(len(sentences), max_len)\n",
    "    mask = mask >= lengths.unsqueeze(1)\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)  # (B,1,1,L)\n",
    "    mask = mask.float() * -1e9\n",
    "\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return padded, mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36a924e3-b2a1-4a4b-b7a3-460b9a25ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = SentenceDataset(df)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
