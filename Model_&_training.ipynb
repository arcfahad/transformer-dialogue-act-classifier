{"cells":[{"cell_type":"markdown","source":["# Transformer-Based Dialogue Act Classification (From Scratch)\n","\n","## Problem Statement\n","\n","The objective of this project is to perform **sentence-level dialogue act classification** using a **Transformer encoder implemented from scratch**. Given a single sentence as input, the model predicts the corresponding dialogue act class. Pretrained Transformer models are deliberately avoided to demonstrate complete conceptual understanding of the architecture and training process.\n","\n","---\n","\n","## Data Preprocessing\n","\n","The original dataset is dialogue-level, where each dialogue contains multiple utterances with associated act labels. Since Transformers operate on fixed training units, I convert the data into **one sentence → one label** format.\n","\n","Preprocessing involves:\n","- Parsing dialogues into individual sentences\n","- Aligning each sentence with its dialogue act\n","- Lowercasing text\n","- Tokenizing into word-level tokens\n","- Storing only token lists and labels (no embeddings)\n","\n","The output of preprocessing is stored as pickle files containing tokenized sentences and integer labels.\n","\n","---\n","\n","## Word Embeddings\n","\n","I use **Word2Vec Skip-Gram** to obtain dense static word embeddings. One-hot encoding is avoided due to sparsity and lack of semantic information. Embeddings are trained offline and saved as `KeyedVectors`.\n","\n","During training and inference:\n","- Tokens are converted to vectors dynamically inside the dataset\n","- Sentence embeddings are not precomputed\n","- This design is memory-efficient and scalable\n","\n","---\n","\n","## Dataset Design\n","\n","The custom dataset class:\n","- Loads tokenized sentences and labels\n","- Converts tokens to Word2Vec vectors at runtime\n","- Returns a variable-length tensor per sentence\n","\n","If no token is found in the vocabulary, a zero vector is used to avoid empty inputs.\n","\n","---\n","\n","## Padding and Attention Masking\n","\n","Sentences have variable lengths, so I pad them at batch time using `pad_sequence`. An attention mask is created with shape `(B, 1, 1, L)` where:\n","- Valid tokens have mask value `0`\n","- Padding tokens have mask value `-1e9`\n","\n","This mask is added to attention scores so padded positions are ignored by softmax.\n","\n","---\n","\n","## Positional Encoding\n","\n","Since self-attention does not encode word order, I add **sinusoidal positional encoding** to input embeddings. Positional encodings are:\n","- Precomputed once up to the maximum sequence length\n","- Stored as a non-trainable buffer\n","- Added only at the encoder input\n","\n","This preserves sequence order without additional parameters.\n","\n","---\n","\n","## Transformer Encoder Architecture\n","\n","Each encoder block consists of:\n","- Multi-head self-attention with scaled dot-product attention\n","- Position-wise feed-forward network\n","- Residual connections and layer normalization\n","\n","Multiple encoder blocks are stacked to progressively contextualize token representations. The attention mask is applied before softmax to suppress padding tokens.\n","\n","---\n","\n","## Sentence Representation and Pooling\n","\n","The encoder produces token-level contextual embeddings. To obtain a sentence-level representation, I apply **masked mean pooling**:\n","- Padding positions are zeroed out\n","- Valid token embeddings are summed\n","- The sum is divided by the number of valid tokens\n","\n","This ensures padding does not influence the sentence embedding.\n","\n","---\n","\n","## Classification Head\n","\n","The pooled sentence embedding is passed through a linear layer mapping `d_model` to `num_classes`, producing logits for dialogue act prediction.\n","\n","---\n","\n","## Label Handling and Class Imbalance\n","\n","Dialogue act labels are converted to a contiguous zero-indexed range `[0, C-1]`, as required by `CrossEntropyLoss`.\n","\n","To handle class imbalance, I compute inverse-frequency class weights with smoothing and use them in the loss function. This reduces bias toward dominant classes and improves minority-class learning.\n","\n","---\n","\n","## Training and Validation\n","\n","The model is trained using the Adam optimizer with gradient clipping for stability. Training loss is logged at regular intervals.\n","\n","After each epoch, I evaluate the model on a validation set and compute:\n","- Validation loss\n","- Accuracy\n","- Macro F1-score\n","\n","Macro F1 is emphasized because it treats all classes equally. The model checkpoint with the highest validation Macro F1 is saved.\n","\n","---\n","\n","## Testing\n","\n","After training, the best-performing model is evaluated once on the test set. Reported metrics include:\n","- Accuracy\n","- Macro F1-score\n","- Confusion matrix\n","- Classification report\n","\n","This provides an unbiased estimate of generalization performance.\n","\n","---\n","\n","## Inference\n","\n","A prediction function is implemented to:\n","- Tokenize a user-provided sentence\n","- Convert tokens to Word2Vec embeddings\n","- Perform a forward pass through the model\n","- Output the predicted dialogue act and class probabilities\n","\n","This enables direct usage of the trained model on unseen text.\n","\n","---\n","\n","## Summary\n","\n","This project demonstrates a complete Transformer encoder implemented from first principles, including dynamic embeddings, attention masking, positional encoding, sentence pooling, class imbalance handling, and rigorous evaluation. The design prioritizes conceptual clarity, correctness, and reproducibility."],"metadata":{"id":"CWG-BnD3gbet"},"id":"CWG-BnD3gbet"},{"cell_type":"code","execution_count":2,"id":"tnMRU3stCWsY","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12426,"status":"ok","timestamp":1767368070193,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"tnMRU3stCWsY","outputId":"a27dc4ec-08ad-4458-d067-8576fae7426b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n","Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gensim\n","Successfully installed gensim-4.4.0\n"]}],"source":["!pip install gensim"]},{"cell_type":"code","execution_count":3,"id":"775f3dbd-f879-4d51-979e-957fd5d0df4e","metadata":{"executionInfo":{"elapsed":14569,"status":"ok","timestamp":1767368084770,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"775f3dbd-f879-4d51-979e-957fd5d0df4e"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import gensim\n","import torch\n","import torch.nn as nn\n","import torch.nn.utils.rnn\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","from gensim.models import KeyedVectors"]},{"cell_type":"code","execution_count":4,"id":"xaNO66qGCMgH","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41855,"status":"ok","timestamp":1767368126627,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"xaNO66qGCMgH","outputId":"e2879d0f-4adc-4ee0-8132-b1113ea60203"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"id":"d82443c6-e921-429b-aaf0-34bbca06cd0f","metadata":{"id":"d82443c6-e921-429b-aaf0-34bbca06cd0f","executionInfo":{"status":"ok","timestamp":1767368132419,"user_tz":-330,"elapsed":5797,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["wv = KeyedVectors.load(\"/content/drive/MyDrive/Transformer-Model/word2vec-256-dim.kv\")\n","\n","df = pd.read_pickle(\"/content/drive/MyDrive/Transformer-Model/train_clean_tokens_and_labels_act.pkl\")\n","df_val = pd.read_pickle(\"/content/drive/MyDrive/Transformer-Model/val_clean_tokens_and_labels_act.pkl\")\n","df_test = pd.read_pickle(\"/content/drive/MyDrive/Transformer-Model/test_clean_tokens_and_labels_act.pkl\")\n","\n","# Recalculate max_len to consider all datasets (train, val, test) and add a buffer\n","max_len_train = max(len(s) for s in df[\"sentence\"])\n","max_len_val = max(len(s) for s in df_val[\"sentence\"])\n","max_len_test = max(len(s) for s in df_test[\"sentence\"])\n","max_len = max(max_len_train, max_len_val, max_len_test) + 10 # Added a buffer of 10\n","\n","df[\"act\"] = df[\"act\"] - 1\n","df_val[\"act\"] = df_val[\"act\"] - 1\n","df_test[\"act\"] = df_test[\"act\"] - 1\n","\n","num_classes = df[\"act\"].nunique()\n","\n","alpha = 0.75\n","class_counts = df[\"act\"].value_counts().sort_index().values\n","weights = torch.tensor((1.0 / class_counts)**alpha, dtype=torch.float32)\n","weights = weights / weights.sum()"]},{"cell_type":"code","execution_count":6,"id":"64f97372-68d9-4ccd-8f92-7471d385020b","metadata":{"id":"64f97372-68d9-4ccd-8f92-7471d385020b","executionInfo":{"status":"ok","timestamp":1767368132443,"user_tz":-330,"elapsed":15,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["class SentenceDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, wv):\n","        self.sentences = df[\"sentence\"].tolist()\n","        self.labels = df['act'].tolist()\n","        self.wv = wv\n","        self.embedding_dim = wv.vector_size\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        tokens = self.sentences[idx]\n","\n","        vectors = []\n","        for token in tokens:\n","            if token in self.wv:\n","                vectors.append(torch.tensor(self.wv[token], dtype=torch.float32))\n","\n","        if len(vectors) == 0:\n","            vectors.append(torch.zeros(self.embedding_dim))\n","\n","        sentence_tensor = torch.stack(vectors)   # (L, d_model)\n","        label = int(self.labels[idx])\n","\n","        return sentence_tensor, label"]},{"cell_type":"code","execution_count":7,"id":"65d1ba36-1550-4830-8021-0d494ade9ef9","metadata":{"id":"65d1ba36-1550-4830-8021-0d494ade9ef9","executionInfo":{"status":"ok","timestamp":1767368132615,"user_tz":-330,"elapsed":6,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["def collate_fn(batch):\n","    # batch = [(sentence_tensor, label), ...]\n","\n","    sentences, labels = zip(*batch)  # unzip\n","\n","    lengths = torch.tensor([x.shape[0] for x in sentences])  # (B,)\n","\n","    # Pad sentence tensors\n","    padded = pad_sequence(sentences, batch_first=True).float()  # (B, L, d_model)\n","\n","    # Create attention mask\n","    max_len = padded.shape[1]\n","    mask = torch.arange(max_len, device=padded.device).expand(len(sentences), max_len)\n","    mask = mask >= lengths.unsqueeze(1)\n","    mask = mask.unsqueeze(1).unsqueeze(2)  # (B,1,1,L)\n","    mask = mask.float() * -1e9\n","\n","\n","    labels = torch.tensor(labels, dtype=torch.long)\n","\n","    return padded, mask, labels"]},{"cell_type":"code","execution_count":8,"id":"b893a723-a409-44ab-af9c-8b0e1b8fb174","metadata":{"id":"b893a723-a409-44ab-af9c-8b0e1b8fb174","executionInfo":{"status":"ok","timestamp":1767368132620,"user_tz":-330,"elapsed":9,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, max_len, d_model):\n","        super().__init__()\n","\n","        PE = np.zeros((max_len, d_model))\n","\n","        for pos in range(max_len):\n","            for i in range(d_model // 2):\n","                PE[pos, 2*i] = np.sin(pos / (10000 ** (2*i / d_model)))\n","                PE[pos, 2*i + 1] = np.cos(pos / (10000 ** (2*i / d_model)))\n","\n","        # convert to tensor\n","        PE = torch.tensor(PE, dtype=torch.float32)\n","\n","        # register as buffer (not parameter)\n","        self.register_buffer(\"PE\", PE)\n","\n","    def forward(self, x):\n","\n","        # shape of x is (B, L, d_model)\n","        L = x.size(1)\n","        return x + self.PE[:L]"]},{"cell_type":"code","execution_count":9,"id":"46108438-76ff-48d8-a187-9add25a597d9","metadata":{"id":"46108438-76ff-48d8-a187-9add25a597d9","executionInfo":{"status":"ok","timestamp":1767368134446,"user_tz":-330,"elapsed":15,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["class MultiHeadSelfAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n","        self.W_Q = nn.Linear(d_model, d_model, bias=False)\n","        self.W_K = nn.Linear(d_model, d_model, bias=False)\n","        self.W_V = nn.Linear(d_model, d_model, bias=False)\n","        self.W_O = nn.Linear(d_model, d_model, bias=False)\n","\n","    def forward(self, x, mask=None):\n","        # x has a shape of (batch, sequence_length, model_dimension)\n","        B = x.shape[0]\n","        L = x.shape[1]\n","\n","        Q = self.W_Q(x) # all are of the shape (B, L, d_model)\n","        K = self.W_K(x)\n","        V = self.W_V(x)\n","\n","\n","        # creating multiple heads from these single heads, ie. Q, K, V by\n","        # reshaping the shape to (B, L, num_heads, head_dim) where num_heads*head_dims\n","        # is equal to the d_model.\n","        Q = Q.reshape(B, L, self.num_heads, self.head_dim)\n","        K = K.reshape(B, L, self.num_heads, self.head_dim)\n","        V = V.reshape(B, L, self.num_heads, self.head_dim)\n","\n","        # rearranging the dimensions to (B, num_heads, L, head_dim)\n","        Q = Q.permute(0, 2, 1, 3)\n","        K = K.permute(0, 2, 1, 3)\n","        V = V.permute(0, 2, 1, 3)\n","\n","        # calculating the scaled attention scores\n","        scores = Q @ K.transpose(-2, -1) # dim = (B, num_heads, L, L)\n","        scores = scores / (self.head_dim**0.5)\n","        if mask is not None:\n","            scores = scores + mask\n","        attention_weights = torch.softmax(scores, dim=-1) #dim = (B, num_heads, L, L)\n","        out = attention_weights @ V\n","\n","        # making the output dimensions equal to the input dimensions.\n","        out = out.permute(0, 2, 1, 3)\n","        out = out.reshape(B, L, self.d_model)\n","\n","        # applying the output projection\n","        out = self.W_O(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":10,"id":"752dbf43-da2b-448e-8c32-6e1fec6e64ae","metadata":{"id":"752dbf43-da2b-448e-8c32-6e1fec6e64ae","executionInfo":{"status":"ok","timestamp":1767368137820,"user_tz":-330,"elapsed":47,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model):\n","        super().__init__()\n","        self.network = nn.Sequential(\n","            nn.Linear(d_model, 4*d_model), # Changed from 2*d_model to 4*d_model for standard Transformer FFN\n","            nn.ReLU(),\n","            nn.Linear(4*d_model, d_model)  # Changed from 2*d_model to 4*d_model for standard Transformer FFN\n","        )\n","\n","    def forward(self, x):\n","        out = self.network(x)\n","        return out"]},{"cell_type":"code","execution_count":11,"id":"fb6e54f0-7b75-404f-8fd0-910f6a11fb7a","metadata":{"id":"fb6e54f0-7b75-404f-8fd0-910f6a11fb7a","executionInfo":{"status":"ok","timestamp":1767368141247,"user_tz":-330,"elapsed":14,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","\n","        self.attention = MultiHeadSelfAttention(d_model, num_heads)\n","        self.feed_forward = FeedForward(d_model)\n","        self.layer_norm1 = nn.LayerNorm(d_model)\n","        self.layer_norm2 = nn.LayerNorm(d_model)\n","\n","    def forward(self, x, mask=None):\n","\n","        attn_out = self.attention(x, mask)\n","\n","        x = self.layer_norm1(attn_out + x)\n","\n","        ffn_out = self.feed_forward(x)\n","\n","        x = self.layer_norm2(ffn_out + x)\n","\n","        return x"]},{"cell_type":"code","execution_count":12,"id":"2dad562a-b979-4ee5-84dc-69c9273f11d7","metadata":{"id":"2dad562a-b979-4ee5-84dc-69c9273f11d7","executionInfo":{"status":"ok","timestamp":1767368144422,"user_tz":-330,"elapsed":7,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, d_model, num_heads, num_layers, max_len):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.positional_encoding = PositionalEncoding(max_len, d_model)\n","        self.blocks = nn.ModuleList([EncoderBlock(d_model, num_heads) for i in range(num_layers)])\n","\n","    def forward(self, x, mask=None):\n","        x = self.positional_encoding(x)\n","\n","        for block in self.blocks:\n","            x = block(x, mask)\n","        return x"]},{"cell_type":"code","execution_count":13,"id":"e054c08e-ce48-4475-bf30-59e6f8f99ea3","metadata":{"id":"e054c08e-ce48-4475-bf30-59e6f8f99ea3","executionInfo":{"status":"ok","timestamp":1767368222664,"user_tz":-330,"elapsed":12,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["class SentenceActModel(nn.Module):\n","    def __init__(self, d_model, num_heads, num_layers, num_classes, max_len):\n","        super().__init__()\n","\n","        # Encoder backbone\n","        self.encoder = Encoder(d_model, num_heads, num_layers, max_len=max_len)\n","\n","        # Classification head\n","        self.classifier = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x, mask):\n","        \"\"\"\n","        x:    (B, L, d_model)\n","        mask: (B, 1, 1, L)\n","        \"\"\"\n","\n","        # Encoder\n","        encoded = self.encoder(x, mask)  # (B, L, d_model)\n","\n","        # mask for pooling\n","        # mask == 0 → valid tokens\n","        valid_mask = (mask == 0).squeeze(1).squeeze(1)  # (B, L)\n","\n","        # Zero-out padding embeddings\n","        valid_mask = valid_mask.unsqueeze(-1)           # (B, L, 1)\n","        encoded = encoded * valid_mask                   # (B, L, d_model)\n","\n","        # Sum over tokens\n","        summed = encoded.sum(dim=1)                      # (B, d_model)\n","\n","        # Count real tokens\n","        lengths = valid_mask.sum(dim=1)                  # (B, 1)\n","        lengths = lengths.clamp(min=1)                   # avoid divide-by-zero\n","\n","        # Mean pooling\n","        sentence_embedding = summed / lengths            # (B, d_model)\n","\n","        # Classification\n","        logits = self.classifier(sentence_embedding)     # (B, num_classes)\n","\n","        return logits"]},{"cell_type":"code","execution_count":16,"id":"56c690e1-f3a4-4be5-8ecf-92002f3089fe","metadata":{"id":"56c690e1-f3a4-4be5-8ecf-92002f3089fe","executionInfo":{"status":"ok","timestamp":1767368319423,"user_tz":-330,"elapsed":57,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["dataset = SentenceDataset(df, wv)\n","loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":17,"id":"68660011-2ece-4fcd-b1b8-d7d708264633","metadata":{"id":"68660011-2ece-4fcd-b1b8-d7d708264633","executionInfo":{"status":"ok","timestamp":1767368329436,"user_tz":-330,"elapsed":9,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["val_dataset = SentenceDataset(df_val, wv)\n","test_dataset = SentenceDataset(df_test, wv)\n","\n","val_loader = DataLoader(val_dataset,batch_size=32,shuffle=False,collate_fn=collate_fn)\n","\n","test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False,collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":18,"id":"c5ef07b0-7a93-4e63-b879-e25264f086ff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5152,"status":"ok","timestamp":1767368364337,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"c5ef07b0-7a93-4e63-b879-e25264f086ff","outputId":"af8906e7-2ae9-4cf7-c1aa-060ff16c7715"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","model = SentenceActModel(\n","    d_model=256,\n","    num_heads=8,\n","    num_layers=6,\n","    num_classes=num_classes,\n","    max_len=max_len\n",").to(device)\n","\n","criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"]},{"cell_type":"code","execution_count":19,"id":"92832b6c-940d-433b-97d6-0287b09e5032","metadata":{"id":"92832b6c-940d-433b-97d6-0287b09e5032","executionInfo":{"status":"ok","timestamp":1767368398040,"user_tz":-330,"elapsed":220,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def evaluate(model, loader, criterion, device):\n","    model.eval()\n","\n","    total_loss = 0.0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for padded_batch, mask, labels in loader:\n","            padded_batch = padded_batch.to(device)\n","            mask = mask.to(device)\n","            labels = labels.to(device)\n","\n","            logits = model(padded_batch, mask)\n","            loss = criterion(logits, labels)\n","            total_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    avg_loss = total_loss / len(loader)\n","    acc = accuracy_score(all_labels, all_preds)\n","    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n","\n","    return avg_loss, acc, macro_f1"]},{"cell_type":"code","execution_count":20,"id":"f86400b1-3d2d-49ce-bf58-3c4e9c27b073","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f86400b1-3d2d-49ce-bf58-3c4e9c27b073","outputId":"c208cf22-7faf-487a-db92-d8d318aa90e4","executionInfo":{"status":"ok","timestamp":1767368988106,"user_tz":-330,"elapsed":554803,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/8] | Train Loss: 0.7631 | Val Loss: 0.7050 | Val Acc: 0.7523 | Val Macro F1: 0.7019\n","Epoch [2/8] | Train Loss: 0.6590 | Val Loss: 0.7038 | Val Acc: 0.7421 | Val Macro F1: 0.6976\n","Epoch [3/8] | Train Loss: 0.6118 | Val Loss: 0.6593 | Val Acc: 0.7603 | Val Macro F1: 0.7201\n","Epoch [4/8] | Train Loss: 0.5648 | Val Loss: 0.6613 | Val Acc: 0.7546 | Val Macro F1: 0.7167\n","Epoch [5/8] | Train Loss: 0.5081 | Val Loss: 0.6672 | Val Acc: 0.7543 | Val Macro F1: 0.7215\n","Epoch [6/8] | Train Loss: 0.4420 | Val Loss: 0.7260 | Val Acc: 0.7634 | Val Macro F1: 0.7255\n","Epoch [7/8] | Train Loss: 0.3765 | Val Loss: 0.8225 | Val Acc: 0.7677 | Val Macro F1: 0.7266\n","Epoch [8/8] | Train Loss: 0.3219 | Val Loss: 0.8691 | Val Acc: 0.7628 | Val Macro F1: 0.7238\n","\n","FINAL TEST RESULTS\n","Test Loss     : 0.7728\n","Test Accuracy : 0.7846\n","Test Macro F1 : 0.7214\n","\n","Confusion Matrix:\n","[[2750   66  229  489]\n"," [  27 2086   84   13]\n"," [ 246  126  804  102]\n"," [ 192   23   70  433]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.78      0.81      3534\n","           1       0.91      0.94      0.92      2210\n","           2       0.68      0.63      0.65      1278\n","           3       0.42      0.60      0.49       718\n","\n","    accuracy                           0.78      7740\n","   macro avg       0.71      0.74      0.72      7740\n","weighted avg       0.80      0.78      0.79      7740\n","\n"]}],"source":["from sklearn.metrics import confusion_matrix, classification_report\n","\n","num_epochs = 8\n","# =========================\n","# TRAINING + VALIDATION\n","# =========================\n","for epoch in range(num_epochs):\n","\n","    model.train()\n","    total_loss = 0.0\n","\n","    for step, (padded_batch, mask, labels) in enumerate(loader, start=1):\n","        padded_batch = padded_batch.to(device)\n","        mask = mask.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model(padded_batch, mask)\n","        loss = criterion(logits, labels)\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_train_loss = total_loss / len(loader)\n","\n","    # ---------- VALIDATION ----------\n","    val_loss, val_acc, val_f1 = evaluate(\n","        model, val_loader, criterion, device\n","    )\n","\n","    print(\n","        f\"Epoch [{epoch+1}/{num_epochs}] | \"\n","        f\"Train Loss: {avg_train_loss:.4f} | \"\n","        f\"Val Loss: {val_loss:.4f} | \"\n","        f\"Val Acc: {val_acc:.4f} | \"\n","        f\"Val Macro F1: {val_f1:.4f}\"\n","    )\n","\n","# =========================\n","# FINAL TEST (RUN ONCE)\n","# =========================\n","test_loss, test_acc, test_f1 = evaluate(\n","    model, test_loader, criterion, device\n",")\n","\n","print(\"\\nFINAL TEST RESULTS\")\n","print(f\"Test Loss     : {test_loss:.4f}\")\n","print(f\"Test Accuracy : {test_acc:.4f}\")\n","print(f\"Test Macro F1 : {test_f1:.4f}\")\n","\n","# =========================\n","# CONFUSION MATRIX (TEST)\n","# =========================\n","model.eval()\n","y_true, y_pred = [], []\n","\n","with torch.no_grad():\n","    for padded_batch, mask, labels in test_loader:\n","        padded_batch = padded_batch.to(device)\n","        mask = mask.to(device)\n","\n","        logits = model(padded_batch, mask)\n","        preds = torch.argmax(logits, dim=1)\n","\n","        y_pred.extend(preds.cpu().numpy())\n","        y_true.extend(labels.numpy())\n","\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_true, y_pred))\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_true, y_pred))"]},{"cell_type":"code","execution_count":21,"id":"RpzfSoK5HoaC","metadata":{"id":"RpzfSoK5HoaC","executionInfo":{"status":"ok","timestamp":1767369326611,"user_tz":-330,"elapsed":1720,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["import nltk\n","from nltk.tokenize import wordpunct_tokenize\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":23,"id":"_kUykO8uH9Oa","metadata":{"id":"_kUykO8uH9Oa","executionInfo":{"status":"ok","timestamp":1767369944524,"user_tz":-330,"elapsed":40,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"outputs":[],"source":["from nltk.tokenize import wordpunct_tokenize\n","import torch.nn.functional as F\n","\n","def predict_act(sentence, model, wv, device):\n","    model.eval()\n","\n","    tokens = wordpunct_tokenize(sentence.lower())\n","\n","    vectors = [\n","        torch.tensor(wv[t], dtype=torch.float32)\n","        for t in tokens if t in wv\n","    ] or [torch.zeros(wv.vector_size)]\n","\n","    x = torch.stack(vectors).unsqueeze(0).to(device)  # (1, L, d_model)\n","    mask = torch.zeros(1, 1, 1, x.size(1), device=device)\n","\n","    with torch.no_grad():\n","        logits = model(x, mask)\n","        probs = F.softmax(logits, dim=1)\n","\n","    return probs.argmax(dim=1).item(), probs.squeeze(0).cpu().numpy()"]},{"cell_type":"code","source":["id2act = {\n","    0: \"statement\",\n","    1: \"question\",\n","    2: \"request\",\n","    3: \"agreement\"\n","}"],"metadata":{"id":"bD6tdvi_dq5R","executionInfo":{"status":"ok","timestamp":1767370078921,"user_tz":-330,"elapsed":13,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}}},"id":"bD6tdvi_dq5R","execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":27,"id":"AJCuEdFBOoF4","metadata":{"id":"AJCuEdFBOoF4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767370080085,"user_tz":-330,"elapsed":12,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}},"outputId":"c6b67c4f-bdd8-4bd5-e44d-55ffdd100ff5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted act id: 2\n","Predicted act: request\n","Class probabilities: [2.7967757e-04 5.7560736e-03 9.9342334e-01 5.4084347e-04]\n"]}],"source":["sentence = \"Can you please help me with this problem?\"\n","\n","pred_act, probs = predict_act(sentence, model, wv, device)\n","\n","print(\"Predicted act id:\", pred_act)\n","print(\"Predicted act:\", id2act[pred_act])\n","print(\"Class probabilities:\", probs)"]},{"cell_type":"code","source":["tests = [\n","    \"Can you explain this?\",\n","    \"Thank you so much!\",\n","    \"I think this is correct.\",\n","    \"Please send the file.\"\n","]\n","\n","for s in tests:\n","    act, _ = predict_act(s, model, wv, device)\n","    print(f\"{s} -> {id2act[act]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQmqRT_SdyVH","executionInfo":{"status":"ok","timestamp":1767370089652,"user_tz":-330,"elapsed":21,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"}},"outputId":"5325d006-ad1f-48a1-bfc1-86564de3324d"},"id":"rQmqRT_SdyVH","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Can you explain this? -> request\n","Thank you so much! -> agreement\n","I think this is correct. -> statement\n","Please send the file. -> request\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.9"}},"nbformat":4,"nbformat_minor":5}