{"cells":[{"cell_type":"code","execution_count":4,"id":"775f3dbd-f879-4d51-979e-957fd5d0df4e","metadata":{"executionInfo":{"elapsed":13462,"status":"ok","timestamp":1767364843227,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"775f3dbd-f879-4d51-979e-957fd5d0df4e"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import gensim\n","import torch\n","import torch.nn as nn\n","import torch.nn.utils.rnn\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","from gensim.models import KeyedVectors"]},{"cell_type":"code","execution_count":3,"id":"tnMRU3stCWsY","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6609,"status":"ok","timestamp":1767364826269,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"tnMRU3stCWsY","outputId":"49094418-7d23-4bea-b5d6-5f0b239da51a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n","Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gensim\n","Successfully installed gensim-4.4.0\n"]}],"source":["!pip install gensim"]},{"cell_type":"code","execution_count":1,"id":"xaNO66qGCMgH","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40504,"status":"ok","timestamp":1767364807107,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"xaNO66qGCMgH","outputId":"cbeb4b1c-0322-4960-e0be-6468acb2b9ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"d82443c6-e921-429b-aaf0-34bbca06cd0f","metadata":{"id":"d82443c6-e921-429b-aaf0-34bbca06cd0f"},"outputs":[],"source":["wv = KeyedVectors.load(\"/content/drive/MyDrive/Transformer-Model/word2vec-256-dim.kv\")\n","\n","df = pd.read_pickle(\"/content/drive/MyDrive/Transformer-Model/train_clean_tokens_and_labels_act.pkl\")\n","df_val = pd.read_pickle(\"/content/drive/MyDrive/Transformer-Model/val_clean_tokens_and_labels_act.pkl\")\n","df_test = pd.read_pickle(\"/content/drive/MyDrive/Transformer-Model/test_clean_tokens_and_labels_act.pkl\")\n","\n","# Recalculate max_len to consider all datasets (train, val, test) and add a buffer\n","max_len_train = max(len(s) for s in df[\"sentence\"])\n","max_len_val = max(len(s) for s in df_val[\"sentence\"])\n","max_len_test = max(len(s) for s in df_test[\"sentence\"])\n","max_len = max(max_len_train, max_len_val, max_len_test) + 10 # Added a buffer of 10\n","\n","df[\"act\"] = df[\"act\"] - 1\n","df_val[\"act\"] = df_val[\"act\"] - 1\n","df_test[\"act\"] = df_test[\"act\"] - 1\n","\n","num_classes = df[\"act\"].nunique()\n","\n","alpha = 0.75\n","class_counts = df[\"act\"].value_counts().sort_index().values\n","weights = torch.tensor((1.0 / class_counts)**alpha, dtype=torch.float32)\n","weights = weights / weights.sum()"]},{"cell_type":"code","execution_count":null,"id":"091bve5qBu_X","metadata":{"id":"091bve5qBu_X"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"X7q1uupOCgIN","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60,"status":"ok","timestamp":1767346811380,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"X7q1uupOCgIN","outputId":"f3a1c19c-2bea-4be3-f34e-36739ec04bc1"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["num_classes"]},{"cell_type":"code","execution_count":null,"id":"RJPTJ63hDH0z","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1767346812307,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"RJPTJ63hDH0z","outputId":"75c84330-874c-42b8-c207-1a4c3fe58fc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train unique: [np.int64(0), np.int64(1), np.int64(2), np.int64(3)]\n","Val unique: [np.int64(0), np.int64(1), np.int64(2), np.int64(3)]\n","Test unique: [np.int64(0), np.int64(1), np.int64(2), np.int64(3)]\n","Train min/max: 0 3\n","Val min/max: 0 3\n","Test min/max: 0 3\n","Any NaN in train: False\n","Any NaN in val: False\n","Any NaN in test: False\n"]}],"source":["print(\"Train unique:\", sorted(df[\"act\"].unique()))\n","print(\"Val unique:\", sorted(df_val[\"act\"].unique()))\n","print(\"Test unique:\", sorted(df_test[\"act\"].unique()))\n","\n","print(\"Train min/max:\", df[\"act\"].min(), df[\"act\"].max())\n","print(\"Val min/max:\", df_val[\"act\"].min(), df_val[\"act\"].max())\n","print(\"Test min/max:\", df_test[\"act\"].min(), df_test[\"act\"].max())\n","\n","print(\"Any NaN in train:\", df[\"act\"].isna().any())\n","print(\"Any NaN in val:\", df_val[\"act\"].isna().any())\n","print(\"Any NaN in test:\", df_test[\"act\"].isna().any())"]},{"cell_type":"code","execution_count":null,"id":"64f97372-68d9-4ccd-8f92-7471d385020b","metadata":{"id":"64f97372-68d9-4ccd-8f92-7471d385020b"},"outputs":[],"source":["class SentenceDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, wv):\n","        self.sentences = df[\"sentence\"].tolist()\n","        self.labels = df['act'].tolist()\n","        self.wv = wv\n","        self.embedding_dim = wv.vector_size\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        tokens = self.sentences[idx]\n","\n","        vectors = []\n","        for token in tokens:\n","            if token in self.wv:\n","                vectors.append(torch.tensor(self.wv[token], dtype=torch.float32))\n","\n","        if len(vectors) == 0:\n","            vectors.append(torch.zeros(self.embedding_dim))\n","\n","        sentence_tensor = torch.stack(vectors)   # (L, d_model)\n","        label = int(self.labels[idx])\n","\n","        return sentence_tensor, label"]},{"cell_type":"code","execution_count":null,"id":"65d1ba36-1550-4830-8021-0d494ade9ef9","metadata":{"id":"65d1ba36-1550-4830-8021-0d494ade9ef9"},"outputs":[],"source":["def collate_fn(batch):\n","    # batch = [(sentence_tensor, label), ...]\n","\n","    sentences, labels = zip(*batch)  # unzip\n","\n","    lengths = torch.tensor([x.shape[0] for x in sentences])  # (B,)\n","\n","    # Pad sentence tensors\n","    padded = pad_sequence(sentences, batch_first=True).float()  # (B, L, d_model)\n","\n","    # Create attention mask\n","    max_len = padded.shape[1]\n","    mask = torch.arange(max_len, device=padded.device).expand(len(sentences), max_len)\n","    mask = mask >= lengths.unsqueeze(1)\n","    mask = mask.unsqueeze(1).unsqueeze(2)  # (B,1,1,L)\n","    mask = mask.float() * -1e9\n","\n","\n","    labels = torch.tensor(labels, dtype=torch.long)\n","\n","    return padded, mask, labels"]},{"cell_type":"code","execution_count":null,"id":"b893a723-a409-44ab-af9c-8b0e1b8fb174","metadata":{"id":"b893a723-a409-44ab-af9c-8b0e1b8fb174"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, max_len, d_model):\n","        super().__init__()\n","\n","        PE = np.zeros((max_len, d_model))\n","\n","        for pos in range(max_len):\n","            for i in range(d_model // 2):\n","                PE[pos, 2*i] = np.sin(pos / (10000 ** (2*i / d_model)))\n","                PE[pos, 2*i + 1] = np.cos(pos / (10000 ** (2*i / d_model)))\n","\n","        # convert to tensor\n","        PE = torch.tensor(PE, dtype=torch.float32)\n","\n","        # register as buffer (not parameter)\n","        self.register_buffer(\"PE\", PE)\n","\n","    def forward(self, x):\n","\n","        # shape of x is (B, L, d_model)\n","        L = x.size(1)\n","        return x + self.PE[:L]"]},{"cell_type":"code","execution_count":null,"id":"46108438-76ff-48d8-a187-9add25a597d9","metadata":{"id":"46108438-76ff-48d8-a187-9add25a597d9"},"outputs":[],"source":["class MultiHeadSelfAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.head_dim = d_model // num_heads\n","        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n","        self.W_Q = nn.Linear(d_model, d_model, bias=False)\n","        self.W_K = nn.Linear(d_model, d_model, bias=False)\n","        self.W_V = nn.Linear(d_model, d_model, bias=False)\n","        self.W_O = nn.Linear(d_model, d_model, bias=False)\n","\n","    def forward(self, x, mask=None):\n","        # x has a shape of (batch, sequence_length, model_dimension)\n","        B = x.shape[0]\n","        L = x.shape[1]\n","\n","        Q = self.W_Q(x) # all are of the shape (B, L, d_model)\n","        K = self.W_K(x)\n","        V = self.W_V(x)\n","\n","\n","        # creating multiple heads from these single heads, ie. Q, K, V by\n","        # reshaping the shape to (B, L, num_heads, head_dim) where num_heads*head_dims\n","        # is equal to the d_model.\n","        Q = Q.reshape(B, L, self.num_heads, self.head_dim)\n","        K = K.reshape(B, L, self.num_heads, self.head_dim)\n","        V = V.reshape(B, L, self.num_heads, self.head_dim)\n","\n","        # rearranging the dimensions to (B, num_heads, L, head_dim)\n","        Q = Q.permute(0, 2, 1, 3)\n","        K = K.permute(0, 2, 1, 3)\n","        V = V.permute(0, 2, 1, 3)\n","\n","        # calculating the scaled attention scores\n","        scores = Q @ K.transpose(-2, -1) # dim = (B, num_heads, L, L)\n","        scores = scores / (self.head_dim**0.5)\n","        if mask is not None:\n","            scores = scores + mask\n","        attention_weights = torch.softmax(scores, dim=-1) #dim = (B, num_heads, L, L)\n","        out = attention_weights @ V\n","\n","        # making the output dimensions equal to the input dimensions.\n","        out = out.permute(0, 2, 1, 3)\n","        out = out.reshape(B, L, self.d_model)\n","\n","        # applying the output projection\n","        out = self.W_O(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":null,"id":"752dbf43-da2b-448e-8c32-6e1fec6e64ae","metadata":{"id":"752dbf43-da2b-448e-8c32-6e1fec6e64ae"},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model):\n","        super().__init__()\n","        self.network = nn.Sequential(\n","            nn.Linear(d_model, 4*d_model), # Changed from 2*d_model to 4*d_model for standard Transformer FFN\n","            nn.ReLU(),\n","            nn.Linear(4*d_model, d_model)  # Changed from 2*d_model to 4*d_model for standard Transformer FFN\n","        )\n","\n","    def forward(self, x):\n","        out = self.network(x)\n","        return out"]},{"cell_type":"code","execution_count":null,"id":"fb6e54f0-7b75-404f-8fd0-910f6a11fb7a","metadata":{"id":"fb6e54f0-7b75-404f-8fd0-910f6a11fb7a"},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","\n","        self.attention = MultiHeadSelfAttention(d_model, num_heads)\n","        self.feed_forward = FeedForward(d_model)\n","        self.layer_norm1 = nn.LayerNorm(d_model)\n","        self.layer_norm2 = nn.LayerNorm(d_model)\n","\n","    def forward(self, x, mask=None):\n","\n","        attn_out = self.attention(x, mask)\n","\n","        x = self.layer_norm1(attn_out + x)\n","\n","        ffn_out = self.feed_forward(x)\n","\n","        x = self.layer_norm2(ffn_out + x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"2dad562a-b979-4ee5-84dc-69c9273f11d7","metadata":{"id":"2dad562a-b979-4ee5-84dc-69c9273f11d7"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, d_model, num_heads, num_layers, max_len):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.positional_encoding = PositionalEncoding(max_len, d_model)\n","        self.blocks = nn.ModuleList([EncoderBlock(d_model, num_heads) for i in range(num_layers)])\n","\n","    def forward(self, x, mask=None):\n","        x = self.positional_encoding(x)\n","\n","        for block in self.blocks:\n","            x = block(x, mask)\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"e054c08e-ce48-4475-bf30-59e6f8f99ea3","metadata":{"id":"e054c08e-ce48-4475-bf30-59e6f8f99ea3"},"outputs":[],"source":["class SentenceActModel(nn.Module):\n","    def __init__(self, d_model, num_heads, num_layers, num_classes, max_len):\n","        super().__init__()\n","\n","        # Encoder backbone\n","        self.encoder = Encoder(d_model, num_heads, num_layers, max_len=max_len)\n","\n","        # Classification head\n","        self.classifier = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x, mask):\n","        \"\"\"\n","        x:    (B, L, d_model)\n","        mask: (B, 1, 1, L)\n","        \"\"\"\n","\n","        # Step 1: Encoder\n","        encoded = self.encoder(x, mask)  # (B, L, d_model)\n","\n","        # Step 2: Prepare mask for pooling\n","        # mask == 0 → valid tokens\n","        valid_mask = (mask == 0).squeeze(1).squeeze(1)  # (B, L)\n","\n","        # Step 3: Zero-out padding embeddings\n","        valid_mask = valid_mask.unsqueeze(-1)           # (B, L, 1)\n","        encoded = encoded * valid_mask                   # (B, L, d_model)\n","\n","        # Step 4: Sum over tokens\n","        summed = encoded.sum(dim=1)                      # (B, d_model)\n","\n","        # Step 5: Count real tokens\n","        lengths = valid_mask.sum(dim=1)                  # (B, 1)\n","        lengths = lengths.clamp(min=1)                   # avoid divide-by-zero\n","\n","        # Step 6: Mean pooling\n","        sentence_embedding = summed / lengths            # (B, d_model)\n","\n","        # Step 7: Classification\n","        logits = self.classifier(sentence_embedding)     # (B, num_classes)\n","\n","        return logits"]},{"cell_type":"code","execution_count":null,"id":"56c690e1-f3a4-4be5-8ecf-92002f3089fe","metadata":{"id":"56c690e1-f3a4-4be5-8ecf-92002f3089fe"},"outputs":[],"source":["dataset = SentenceDataset(df, wv)\n","loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"id":"68660011-2ece-4fcd-b1b8-d7d708264633","metadata":{"id":"68660011-2ece-4fcd-b1b8-d7d708264633"},"outputs":[],"source":["val_dataset = SentenceDataset(df_val, wv)\n","test_dataset = SentenceDataset(df_test, wv)\n","\n","val_loader = DataLoader(val_dataset,batch_size=16,shuffle=False,collate_fn=collate_fn)\n","\n","test_loader = DataLoader(test_dataset,batch_size=16,shuffle=False,collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"id":"c5ef07b0-7a93-4e63-b879-e25264f086ff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5452,"status":"ok","timestamp":1767353883359,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"c5ef07b0-7a93-4e63-b879-e25264f086ff","outputId":"9449d99b-e5a9-4948-b6a0-f44c635de471"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","model = SentenceActModel(\n","    d_model=256,\n","    num_heads=8,\n","    num_layers=6,\n","    num_classes=num_classes,\n","    max_len=max_len\n",").to(device)\n","\n","criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n","optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)"]},{"cell_type":"code","execution_count":null,"id":"92832b6c-940d-433b-97d6-0287b09e5032","metadata":{"id":"92832b6c-940d-433b-97d6-0287b09e5032"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def evaluate(model, loader, criterion, device):\n","    model.eval()\n","\n","    total_loss = 0.0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for padded_batch, mask, labels in loader:\n","            padded_batch = padded_batch.to(device)\n","            mask = mask.to(device)\n","            labels = labels.to(device)\n","\n","            logits = model(padded_batch, mask)\n","            loss = criterion(logits, labels)\n","            total_loss += loss.item()\n","\n","            preds = torch.argmax(logits, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    avg_loss = total_loss / len(loader)\n","    acc = accuracy_score(all_labels, all_preds)\n","    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n","\n","    return avg_loss, acc, macro_f1"]},{"cell_type":"code","execution_count":null,"id":"f86400b1-3d2d-49ce-bf58-3c4e9c27b073","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"f86400b1-3d2d-49ce-bf58-3c4e9c27b073","outputId":"4211619d-befe-429b-8708-f3ded00fa85e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10] | Train Loss: 0.7670 | Val Loss: 0.7359 | Val Acc: 0.7356 | Val Macro F1: 0.6754\n","Epoch [2/10] | Train Loss: 0.6606 | Val Loss: 0.7044 | Val Acc: 0.7068 | Val Macro F1: 0.6774\n","Epoch [3/10] | Train Loss: 0.6215 | Val Loss: 0.6515 | Val Acc: 0.7535 | Val Macro F1: 0.7148\n","Epoch [4/10] | Train Loss: 0.5845 | Val Loss: 0.6571 | Val Acc: 0.7679 | Val Macro F1: 0.7201\n","Epoch [5/10] | Train Loss: 0.5404 | Val Loss: 0.6597 | Val Acc: 0.7551 | Val Macro F1: 0.7216\n","Epoch [6/10] | Train Loss: 0.4886 | Val Loss: 0.6610 | Val Acc: 0.7568 | Val Macro F1: 0.7228\n","Epoch [7/10] | Train Loss: 0.4301 | Val Loss: 0.7467 | Val Acc: 0.7795 | Val Macro F1: 0.7300\n","Epoch [8/10] | Train Loss: 0.3758 | Val Loss: 0.8269 | Val Acc: 0.7713 | Val Macro F1: 0.7280\n","Epoch [9/10] | Train Loss: 0.3258 | Val Loss: 0.9420 | Val Acc: 0.7659 | Val Macro F1: 0.7270\n","Epoch [10/10] | Train Loss: 0.2888 | Val Loss: 1.1618 | Val Acc: 0.7616 | Val Macro F1: 0.7140\n","\n","FINAL TEST RESULTS\n","Test Loss     : 1.0047\n","Test Accuracy : 0.8005\n","Test Macro F1 : 0.7304\n","\n","Confusion Matrix:\n","[[2987   51  166  330]\n"," [  43 2062   83   22]\n"," [ 341  116  742   79]\n"," [ 243   17   53  405]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.85      0.84      3534\n","           1       0.92      0.93      0.93      2210\n","           2       0.71      0.58      0.64      1278\n","           3       0.48      0.56      0.52       718\n","\n","    accuracy                           0.80      7740\n","   macro avg       0.73      0.73      0.73      7740\n","weighted avg       0.80      0.80      0.80      7740\n","\n"]}],"source":["from sklearn.metrics import confusion_matrix, classification_report\n","\n","num_epochs = 10\n","\n","# =========================\n","# TRAINING + VALIDATION\n","# =========================\n","for epoch in range(num_epochs):\n","\n","    model.train()\n","    total_loss = 0.0\n","\n","    for step, (padded_batch, mask, labels) in enumerate(loader, start=1):\n","        padded_batch = padded_batch.to(device)\n","        mask = mask.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        logits = model(padded_batch, mask)\n","        loss = criterion(logits, labels)\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_train_loss = total_loss / len(loader)\n","\n","    # ---------- VALIDATION ----------\n","    val_loss, val_acc, val_f1 = evaluate(\n","        model, val_loader, criterion, device\n","    )\n","\n","    print(\n","        f\"Epoch [{epoch+1}/{num_epochs}] | \"\n","        f\"Train Loss: {avg_train_loss:.4f} | \"\n","        f\"Val Loss: {val_loss:.4f} | \"\n","        f\"Val Acc: {val_acc:.4f} | \"\n","        f\"Val Macro F1: {val_f1:.4f}\"\n","    )\n","\n","# =========================\n","# FINAL TEST (RUN ONCE)\n","# =========================\n","test_loss, test_acc, test_f1 = evaluate(\n","    model, test_loader, criterion, device\n",")\n","\n","print(\"\\nFINAL TEST RESULTS\")\n","print(f\"Test Loss     : {test_loss:.4f}\")\n","print(f\"Test Accuracy : {test_acc:.4f}\")\n","print(f\"Test Macro F1 : {test_f1:.4f}\")\n","\n","# =========================\n","# CONFUSION MATRIX (TEST)\n","# =========================\n","model.eval()\n","y_true, y_pred = [], []\n","\n","with torch.no_grad():\n","    for padded_batch, mask, labels in test_loader:\n","        padded_batch = padded_batch.to(device)\n","        mask = mask.to(device)\n","\n","        logits = model(padded_batch, mask)\n","        preds = torch.argmax(logits, dim=1)\n","\n","        y_pred.extend(preds.cpu().numpy())\n","        y_true.extend(labels.numpy())\n","\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_true, y_pred))\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_true, y_pred))"]},{"cell_type":"code","execution_count":null,"id":"RpzfSoK5HoaC","metadata":{"id":"RpzfSoK5HoaC"},"outputs":[],"source":["\n","\n","import nltk\n","from nltk.tokenize import wordpunct_tokenize\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"id":"_kUykO8uH9Oa","metadata":{"id":"_kUykO8uH9Oa"},"outputs":[],"source":["def predict_act(sentence, model, wv, device, max_len):\n","    \"\"\"\n","    sentence: str\n","    returns: predicted act id (int)\n","    \"\"\"\n","\n","    model.eval()\n","\n","    # 1. tokenize\n","    tokens = wordpunct_tokenize(sentence.lower())\n","\n","    # 2. word2vec lookup\n","    vectors = []\n","    for token in tokens:\n","        if token in wv:\n","            vectors.append(torch.tensor(wv[token], dtype=torch.float32))\n","\n","    if len(vectors) == 0:\n","        vectors.append(torch.zeros(wv.vector_size))\n","\n","    sentence_tensor = torch.stack(vectors)  # (L, d_model)\n","\n","    # 3. add batch dimension\n","    sentence_tensor = sentence_tensor.unsqueeze(0).to(device)  # (1, L, d_model)\n","\n","    # 4. create mask\n","    length = sentence_tensor.size(1)\n","    mask = torch.zeros(1, 1, 1, length, device=device)  # no padding → all valid\n","\n","    # 5. forward pass\n","    with torch.no_grad():\n","        logits = model(sentence_tensor, mask)\n","        probs = F.softmax(logits, dim=1)\n","\n","    pred_class = torch.argmax(probs, dim=1).item()\n","\n","    return pred_class, probs.squeeze().cpu().numpy()"]},{"cell_type":"code","execution_count":null,"id":"O8PNUBaROXbj","metadata":{"id":"O8PNUBaROXbj"},"outputs":[],"source":["def predict_act_with_threshold(\n","    sentence,\n","    model,\n","    wv,\n","    device,\n","    max_len,\n","    threshold=0.45\n","):\n","    \"\"\"\n","    Returns:\n","    - act class id OR 'UNCERTAIN'\n","    - probability vector\n","    \"\"\"\n","\n","    pred, probs = predict_act(sentence, model, wv, device, max_len)\n","\n","    confidence = probs[pred]\n","\n","    if confidence < threshold:\n","        return \"UNCERTAIN\", probs\n","\n","    return pred, probs"]},{"cell_type":"code","execution_count":null,"id":"xIB1H5DWIDYk","metadata":{"id":"xIB1H5DWIDYk"},"outputs":[],"source":["sentence =  \"Oh , sorry to hear that . This is quite unusual . I will look into the matter .\""]},{"cell_type":"code","execution_count":null,"id":"YsCKuWmFI3rb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":41,"status":"error","timestamp":1767348876244,"user":{"displayName":"Fahad Nasim","userId":"11578680167371549289"},"user_tz":-330},"id":"YsCKuWmFI3rb","outputId":"d32404cf-7d7d-4040-f0ae-53e389525c39"},"outputs":[{"ename":"RecursionError","evalue":"maximum recursion depth exceeded","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2360386673.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pred, probs = predict_act(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3810906837.py\u001b[0m in \u001b[0;36mpredict_act\u001b[0;34m(sentence, model, wv, device, max_len)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","... last 1 frames repeated, from the frame below ...\n","\u001b[0;32m/tmp/ipython-input-3810906837.py\u001b[0m in \u001b[0;36mpredict_act\u001b[0;34m(sentence, model, wv, device, max_len)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"]}],"source":["pred, probs = predict_act(\n","    sentence,\n","    model,\n","    wv,\n","    device,\n","    max_len\n",")\n","\n","print(\"Prediction:\", pred)\n","print(\"Probabilities:\", probs)"]},{"cell_type":"code","execution_count":null,"id":"AJCuEdFBOoF4","metadata":{"id":"AJCuEdFBOoF4"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.9"}},"nbformat":4,"nbformat_minor":5}